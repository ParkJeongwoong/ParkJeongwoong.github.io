{"pageProps":{"markdown_gitHub":"# [GitHub Blog 개발기] 문서유사도 생성에 대한 고민\r\n\r\n## 문제\r\n\r\n글을 등록하면 다음과 같은 과정을 거친다.\r\n\r\n```\r\n1. 글 등록\r\n2. 각 단어 마다 역색인 생성\r\n3. Term Frequency, Docuemnt Frequency, Document Count를 입력값으로 넣은 TF-IDF로 해당 단어의 중요도 계산\r\n4. 문서끼리 단어를 비교해서 문서 유사도 계산\r\n\r\nTF-IDF는 다음의 계산식으로 구했다.\r\nTF-IDF = TF * log(DC/DF)\r\n```\r\n\r\n1번, 2번 과정만 있었을 때는 문제가 없었지만 3번, 4번 과정을 넣으면서 시간이 오래 걸리는 문제가 생겼다.\r\n\r\n모든 문서의 모든 단어를 비교해야 하기 때문인데, 오랫동안 여러 방법을 고민해봤지만 모든 단어를 비교한다는 틀을 벗어나지 못했기 때문에 근본적인 문제를 해결하진 못했다.\r\n\r\nTerm Frequency는 특정 문서 안의 단어만 비교하면 되지만,\r\n\r\nDocument Frequency는 특정 단어가 포함된 모든 문서와 연관되고,\r\n\r\nDocument Count는 결국 모든 단어에 적용되기 때문에 한 문서의 추가는 모든 단어에 영향이 가게 된다.\r\n\r\n그래서 결국 시간이 오래 걸리는 건 어쩔 수 없다는 결론이 나왔다.\r\n\r\n\r\n\r\n## 수정\r\n\r\n### Lock wait timeout exceeded; try restarting transaction 에러 해결\r\n\r\n어쩔 수 없더라도 Time out 때문에 문서 유사도 생성에 실패하는 문제는 해결해야 했다.\r\n\r\n`Lock wait timeout exceeded; try restarting transaction` 이라는 SQL 오류가 났는데, MariaDB(MySQL)의 timeout 기본값이 50초로 설정되어 있어 나타나는 오류였다.\r\n\r\n`show variables like '%wait_timeout%';`\r\n\r\n라는 명령어로 innodb_lock_wait_timout 값을 확인하고\r\n\r\n`set innodb_lock_wait_timeout= 1800;`\r\n\r\n명령어로 timeout 시간을 30분으로 늘임으로써 해결했다.\r\n\r\n### 단어별 문서 유사도 생성\r\n\r\n이 외에도 문서 유사도를 생성하는 방식을 문서별이 아니라 단어별로 생성하는 것으로 바꿨다.\r\n\r\nDocument Count는 문서 유사도를 생성하는 내내 일정하고\r\n\r\nDocument Frequency는 단어 별로 적용되는 것이기 때문에 Document Frequency를 한 번 구하고 이를 쭉 계산에 써먹는 게 조금 더 나아보였기 때문이다.\r\n\r\n예를 들면,\r\n\r\n```\r\n1번 문서에 단어 A가 2개, B가 1개, C가 3개 있고\r\n2번 문서에 단어 B가 3개, C가 1개, D가 4개 있을 때\r\n\r\n단어 B가 1개, C가 2개 있는 3번 문서를 추가하는 경우\r\n```\r\n\r\n위의 경우,\r\n기존에는 1번 문서를 불러와 3번 문서와 비교해서 1번 문서와 3번 문서 사이의 문서 유사도를 구하고 난 뒤 2번 문서를 불러와 3번 문서와 비교해서 2번 문서와 3번 문서 사이의 문서 유사도를 구했다.\r\n\r\n이러면 1번과 3번을 비교할 때 계산했던 단어 B와 C의 Document Frequency를 2번과 3번을 비교할 때 다시 계산해야 하는데, 단어별로 비교한다면 Document Frerquency를 재계산하는 경우를 피할 수 있었다.\r\n\r\n\r\n\r\n## 개선\r\n\r\nDB에 접근하는 수를 이전보다 줄이긴 했지만 미미한 개선이었다.\r\n\r\n다만 다음 단계로 나아가기 위한 발판은 될 수 있다고 생각한다.\r\n\r\n### 개선안 1. Document Count 제거\r\n\r\n결국 모든 단어에 동일한 Document Count 값이 들어가며, 문서 유사도는 상대값이기 때문에 빠져도 된다고 생각한다.\r\n\r\n만약 Document Count를 뺀다면, 현재 방식에서 손쉽게 큰 속도 개선이 가능하다.\r\n\r\nAS IS : O(M^2) (M: 모든 문서의 모든 단어 수)\r\nTO BE : O(M*M') (M': 다른 문서에서 있는 새로운 문서에 포함된 단어의 수)\r\n\r\n### 개선안 2. Word Count By Document 추가 (Document Count 유지)\r\n\r\n문서에 포함된 단어의 수를 따로 기록해 놓는다면 마찬가지로 개선이 어느정도 속도 개선이 가능하다.\r\n\r\nlog는 밑이 같을 때 진수의 곱셈/나눗셈을 로그의 덧셈/뺄셈으로 분리할 수 있기 때문에,\r\n각 문서마다 [단어의 수 * log(문서의 수)] 만큼을 빼주는 선작업을 추가함으로써 Document Count의 변동으로 인한 문서 유사도의 변동을 반영할 수 있다.\r\n\r\n그러고 나면 개선안 1과 같은 방식으로 문서 유사도를 구할 수 있다.\r\n\r\nAS IS : O(M^2) (M: 모든 문서의 모든 단어 수)\r\nTO BE : O(M*M'+N) (M': 다른 문서에서 있는 새로운 문서에 포함된 단어의 수, N: 문서의 수)\r\n\r\n### 예상 개선 수치\r\n\r\n작성하고 있는 이 글을 제외하고 이 블로그에는 총 67개의 문서에 17,000개의 역색인, 9700개의 단어가 있다. (단어 전처리가 부족해서 독립된 단어가 많이 생성되었다)\r\n\r\nAS IS는 289,000,000번 계산을 해야 하지만\r\n개선안 1을 적용한다면 17,000 * (추정치 500~1,000) = 8,500,000~17,000,000번으로 줄어들 것으로 추정되고\r\n개선안 2를 적용한다면 여기서 67이 더해진 값이 될 것으로 예상된다.","documentTitle":"[GitHub Blog 개발기] 문서유사도 생성에 대한 고민","articleCategory":"Develop","articleId":"15"},"__N_SSG":true}