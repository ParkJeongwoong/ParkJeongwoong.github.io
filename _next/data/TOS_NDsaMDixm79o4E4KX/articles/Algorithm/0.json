{"pageProps":{"markdown":"# 알고리즘 & 자료구조 정리\r\n\r\n(추가할 내용) trie, binary search(lower_bound) /새그먼트 트리\r\n\r\n> https://yomyom0824.tistory.com/58 <-읽어보기 (Trie)\r\n\r\n![image-20210304135155485](Algorithm and Data Structure.assets/image-20210304135155485.png)\r\n\r\n# Array\r\n\r\n| 인덱스 - 데이터                                      |\r\n| ---------------------------------------------------- |\r\n| (파이썬의 리스트)                                    |\r\n| 같은 종류의 데이터를 효율적으로 관리                 |\r\n| 순차적으로 저장                                      |\r\n| 장점 : 인덱스로 인한 빠른 접근                       |\r\n| 단점 : 배열의 크기를 미리 할당(데이터 추가의 어려움) |\r\n| & 데이터 삭제 시 뒤의 데이터가 앞으로 이동           |\r\n\r\n\r\n\r\n# String\r\n\r\n\r\n\r\n\r\n\r\n# Stack\r\n\r\n\r\n\r\n\r\n\r\n# Queue\r\n\r\n선형 큐, 원형 큐, 연결 큐\r\n\r\n- 큐의 활용\r\n  - 버퍼\r\n\r\n\r\n\r\n# List\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n## 연결 리스트\r\n\r\n다음 리스트의 주소를 저장한 리스트 / idx 조정에 따른 손실이 없다\r\n\r\n\r\n\r\n\r\n\r\n# Tree\r\n\r\n## 개념\r\n\r\n- 비선형 구조\r\n  - 1:n의 관계를 가지는 자료구조\r\n  - 계층관계\r\n- 사이클이 없는 **무향 연결 그래프**\r\n\r\n---\r\n\r\n- 최상위 노드(Root)가 존재\r\n- 최상위 노드 아래의 하위 노드들 역시 각각의 subtree이다\r\n\r\n---\r\n\r\n**level** : 0(root)에서 시작 -> 층수\r\n\r\n**degree** : 노드에 연결된 자식의 수\r\n\r\n\r\n\r\n## 이진 트리\r\n\r\n모든 노드가 2개의 서브트리를 갖는 트리\r\n\r\n<u>left child node</u>와 <u>right child node</u>로 나뉨\r\n\r\n\r\n\r\n### 구현\r\n\r\n#### 배열을 이용한 구현\r\n\r\n부모 노드의 번호를 `n`이라고 했을 때, \r\n\r\n자식 노드의 번호를 `2*n`과 `2*n+1`로 선택하는 방식으로 구현(root를 1이라고 가정)\r\n\r\n#### 연결리스트를 이용한 구현\r\n\r\n배열을 이용한 방식보다 더 효율적(메모리 관리, 삭제 및 수정에 있어서 더 효율적)\r\n\r\n`[왼쪽 자식 | key | 오른쪽 자식]` 형태로 구현\r\n\r\n- 모든 원소는 **<u>서로 다른 유일한 키</u>**를 갖는다.\r\n  - 따라서 <u>삽입 시 해당 값이 이미 트리에 있으면 삽입 불가</u>\r\n- 왼쪽 자식은 key보다 작은 값, 오른쪽 자식은 key보다 큰 값\r\n\r\n\r\n\r\n### 완전 이진 트리\r\n\r\n그래프 상 왼쪽부터 채워진 이진 트리 (`heap` 가능)\r\n\r\n#### heap\r\n\r\n**`최고값, 최소값을 구하는 자료구조`**\r\n\r\n- `삽입` : 완전 이진 트리의 마지막 index에 삽입 -> 부모와 비교\r\n\r\n- `삭제` : 루트노드 삭제 -> 마지막 노드 위치를 루트 노드로 -> 자식과 비교\t\r\n\r\n\r\n\r\n\r\n\r\n### 이진 트리 - 순회(traversal)\r\n\r\n순회는 각 노드를 <u>중복되지 않게 전부 방문하는 것</u> -> 비선형 구조인 트리는 특별한 방법 필요\r\n\r\n\r\n\r\n- 기본적인 순회방법\r\n  - **전위 순회** : `부모 노드 - 왼쪽 자식 - 오른쪽 자식` 방문\r\n  - **중위 순회** : `왼쪽 자식 - 부모 노드 - 오른쪽 자식` 방문\r\n  - **후위 순회** : `왼쪽 자식 - 오른쪽 자식 - 부모 노드` 방문\r\n\r\n\r\n\r\n# Set\r\n\r\n\r\n\r\n\r\n\r\n# Hash\r\n\r\n| 해쉬 테이블  (Hash Table)                                 |\r\n| --------------------------------------------------------- |\r\n| 키 - 데이터                                               |\r\n| (파이썬의 딕셔너리)                                       |\r\n| 키 -> [해쉬 함수] -> 해쉬 주소                            |\r\n| 장점 : 저장/읽기 속도가 빠름                              |\r\n| & 키에 대한 데이터 확인이 쉬움                            |\r\n| 단점 : 저장 공간이 많이 필요                              |\r\n| 해쉬 주소 충돌을 해결하기 위한 별도의 자료구조 필요       |\r\n| 용도 : 검색이 많이 필요한 경우 / 저장, 삭제가 빈번한 경우 |\r\n| 캐쉬를 구현하는 경우                                      |\r\n\r\n## Hashing\r\n\r\n특정 항목을 검색하고자 할 때, `탐색키`를 이용하여 산술 연산을 통해 키의 위치를 계산하는 방법\r\n\r\n- 해시 함수\r\n  - `탐색키` -> `위치` 변환 함수\r\n- 해시 테이블\r\n  - 변환된 주소의 위치에 값을 저장한 표\r\n\r\n### 충돌\r\n\r\n> 서로 다른 탐색키가 동일한 주소를 가르킬 경우\r\n\r\n- **해결방법**\r\n  1. 개방 주소법 (Open Addressing)\r\n  2. 체이닝 (Chaining)\r\n\r\n\r\n\r\n1. 체이닝\r\n\r\n   - 하나의 버킷에 하나 이상의 키 값을 가지는 자료를 저장\r\n   - **연결 리스트** 활용\r\n\r\n   \r\n\r\n2. 개방 주소법\r\n\r\n   - 충돌이 발생하면 다음 공간에 빈 공간이 있는지 조사\r\n     - 빈 공간이 있으면 해당 공간에 항목 저장\r\n     - 빈 공간이 없으면 나올 때까지 탐색 반복\r\n\r\n\r\n\r\n\r\n\r\n# Trie\r\n\r\n> 문자열 집합을 표현하는 트리\r\n\r\n- `간선` : 하나의 **문자**에 대응 (중복 X)\r\n\r\n- `리프` : **문자열**\r\n\r\n\r\n\r\n- 사전 순서대로 자식 노드 배열\r\n\r\n## Suffix Tree\r\n\r\n> 하나의 문자열의 모든 접미어를 포함하는 Trie\r\n\r\n- 문자열의 끝에 `$`를 추가해서 종료를 표현\r\n\r\n\r\n\r\n\r\n\r\n# Sorting\r\n\r\n| 알고리즘       | 평균     | 최악 | 메모리 | 안정성 |\r\n| -------------- | -------- | ---- | ------ | ------ |\r\n| Bubble Sort    | n^2      | n^2  | 1      | Y      |\r\n| Selection Sort | n^2      | n^2  | 1      | N      |\r\n| Insert Sort    | n^2      | n^2  | 1      | Y      |\r\n| Shell Sort     | n^1.5    | n^2  | 1      | N      |\r\n| Merge Sort     | nlog2(n) | n^2  | n      | Y      |\r\n| Quick Sort     | nlog2(n) | n^2  | 1      | N      |\r\n| Counting Sort  | n        | n    | n+m    | Y      |\r\n| Heap Sort      | nlog2(n) | n^2  | 1      | N      |\r\n\r\n\r\n\r\n## 버블 정렬\r\n\r\n> 맨 뒤부터 정렬\r\n\r\n인접한 두 원소를 비교하며 자리를 **교환**\r\n\r\n가장 큰 원소부터 마지막 위치에 정렬됨\r\n\r\n\r\n\r\n## 선택 정렬\r\n\r\n> 맨 앞부터 정렬\r\n\r\n최소값 탐색 => 맨 앞과 교체\r\n\r\n반복\r\n\r\n\r\n\r\n## 삽입 정렬\r\n\r\n인덱스에서 숫자를 뽑아서, 인덱스 앞 쪽의 정렬된 부분에서 들어갈 위치를 찾아서 정렬\r\n\r\n- 배열이 작거나, 정렬이 많이 된 경우에는 상당히 빠른 정렬 (탐색에만 시간을 쓰기 때문)\r\n\r\n\r\n\r\n## 셀 정렬\r\n\r\n> 삽입 정렬을 보완한 알고리즘\r\n\r\nhttps://gmlwjd9405.github.io/2018/05/08/algorithm-shell-sort.html\r\n\r\n\r\n\r\n## 퀵 정렬\r\n\r\n>  https://ldgeao99.tistory.com/376\r\n\r\n### 구현\r\n\r\n```python\r\ndef quick(array):\r\n    def sort(left,right):\r\n        if left >= right:\r\n            return\r\n\r\n        mid = partition(left,right) # array 정렬 & mid 찾기\r\n\r\n        sort(left,mid-1)\r\n        sort(mid,right)\r\n\r\n\r\n    def partition(left,right): # 정렬을 하면서 정렬 종료 지점 반환\r\n        pivot = array[(left+right)//2]\r\n        while left <= right:\r\n            while array[left] < pivot:\r\n                left += 1\r\n            while array[right] > pivot:\r\n                right -= 1\r\n            \r\n            if left <= right:\r\n                array[left], array[right] = array[right], array[left]\r\n                left += 1\r\n                right -= 1\r\n        return left\r\n\r\n    return sort(0, len(array) - 1)\r\n\r\n# 실행\r\nimport sys\r\ninput = sys.stdin.readline\r\n\r\nN = int(input())\r\nnums = []\r\nfor i in range(N):\r\n    nums.append(int(input()))\r\n\r\nquick(nums)\r\n\r\nfor i in nums:\r\n    print(i)\r\n```\r\n\r\n\r\n\r\n## 병합 정렬\r\n\r\n### 구현\r\n\r\n```python\r\ndef merge_sort(array):\r\n    # 1에서 분할이 멈춤\r\n    if len(array) <= 1:\r\n        return array\r\n    \r\n    # 분할 \r\n    half = len(array)//2\r\n    # 재귀함수 필요 (끝까지 분할을 위해서)\r\n    left = merge_sort(array[:half])\r\n    right = merge_sort(array[half:])\r\n\r\n    # 병합\r\n    i, j = 0, 0\r\n    result = []\r\n\r\n    while i < len(left) and j < len(right):\r\n        if left[i] > right[j]:\r\n            result.append(right[j])\r\n            j += 1\r\n        else :\r\n            result.append(left[i])\r\n            i += 1\r\n\r\n    # 둘 중 남는 List 값 뒤에 이어 붙이기\r\n    if len(left) > i:\r\n        result += left[i:]\r\n    if len(right) > j:\r\n        result += right[j:]\r\n\r\n    # print(result)\r\n    return result\r\n```\r\n\r\n\r\n\r\n```python\r\ndef merge_sort(array):\r\n    def divied(l,r):\r\n        if l >= r:\r\n            return\r\n\r\n        mid = (l+r)//2\r\n\r\n        divied(l,mid)\r\n        divied(mid+1,r)\r\n        merge(l,r,mid)\r\n\r\n    def merge(l,r,mid):\r\n        i = l\r\n        j = mid+1\r\n        k = 0\r\n        temp = [0] * (r-l+1)\r\n\r\n        while i < mid+1 and j < r+1:\r\n            if array[i] <= array[j]:\r\n                temp[k] = array[i]\r\n                i += 1\r\n            else:\r\n                temp[k] = array[j]\r\n                j += 1\r\n            k += 1\r\n\r\n        while i < mid+1:\r\n            temp[k] = array[i]\r\n            i += 1\r\n            k += 1\r\n        while j < r+1:\r\n            temp[k] = array[j]\r\n            j += 1\r\n            k += 1\r\n\r\n        for i in range(r-l+1):\r\n            array[i+l] = temp[i]\r\n            \r\n    return divied(0,len(array)-1)\r\n\r\na = [3,5,10,2,1,7,3,4,6,5]\r\nmerge_sort(a)\r\nprint(a)\r\n```\r\n\r\n\r\n\r\n```python\r\ndef merge_sort(arr):\r\n    def sort(low, high):\r\n        if high - low < 2:\r\n            return\r\n        mid = (low + high) // 2\r\n        sort(low, mid)\r\n        sort(mid, high)\r\n        merge(low, mid, high)\r\n\r\n    def merge(low, mid, high):\r\n        temp = []\r\n        l, h = low, mid\r\n\r\n        while l < mid and h < high:\r\n            if arr[l] < arr[h]:\r\n                temp.append(arr[l])\r\n                l += 1\r\n            else:\r\n                temp.append(arr[h])\r\n                h += 1\r\n\r\n        while l < mid:\r\n            temp.append(arr[l])\r\n            l += 1\r\n        while h < high:\r\n            temp.append(arr[h])\r\n            h += 1\r\n\r\n        for i in range(low, high):\r\n            arr[i] = temp[i - low]\r\n\r\n    return sort(0, len(arr))\r\n```\r\n\r\n\r\n\r\n\r\n\r\n## 카운팅 정렬\r\n\r\n> O(n) 시간 안에 정렬이 가능한 매우 빠른 정렬\r\n\r\n\r\n\r\n1. 정렬할 리스트 l과 l의 요소를 모두 포함할 최대값 k가 필요\r\n2. 크기가 k+1인 count list 생성\r\n3. 리스트 l의 요소의 갯수를 count에 저장\r\n4. count list의 요소를 누적 요소로 변경 (앞 요소들의 값의 합 + 자신의 값) => indexing을 위해 (count가 0이었던 값들은 어짜피 사용 X)\r\n5. 결과 값을 위한 list 생성\r\n6. **l의 요소를 뒤에서부터 꺼내, 이를 idx로 삼아 count 요소의 값 -1**\r\n   - 안정 정렬을 위해 뒤에서 부터 배치\r\n7. -1한 값을 다시 idx로 삼아 result list에 l의 요소 저장\r\n\r\n\r\n\r\n### 구현\r\n\r\n```python\r\ndef counting(l, k):\r\n    if len(l) < 2:\r\n        return l\r\n\r\n    count = [0] * (k + 1)\r\n    for i in l:\r\n        count[i] += 1\r\n\r\n    for i in range(1, len(count)):\r\n        count[i] += count[i - 1]\r\n\r\n    result = [0] * len(l)\r\n    for i in range(len(l)):\r\n        count[l[-1 - i]] -= 1\r\n        result[count[l[-1 - i]]] = l[-1 - i]\r\n    return result\r\n```\r\n\r\n\r\n\r\n\r\n\r\n## 힙 정렬\r\n\r\n### 구현\r\n\r\n```python\r\nclass heap: # Maxheap\r\n    def __init__(self):\r\n        self.queue = []\r\n\r\n    # 삽입\r\n    def push(self,n): # 값 추가\r\n        self.queue.append(n)\r\n        idx = len(self.queue)-1\r\n        while idx:\r\n            if self.queue[idx] > self.queue[(idx-1)//2]:\r\n                self.queue[idx], self.queue[(idx-1)//2] = self.queue[(idx-1)//2], self.queue[idx]\r\n                idx = (idx-1)//2\r\n            else:\r\n                break\r\n\r\n    # 반환\r\n    def pop(self): # root값 반환 // 이후 맨 마지막 값을 root에 넣고 재정렬\r\n        if len(self.queue) == 0: # 큐가 비어있을 때\r\n            return 0\r\n\r\n        self.queue[0], self.queue[-1] = self.queue[-1], self.queue[0]\r\n        p = self.queue.pop()\r\n        self.heapify()\r\n        return p\r\n\r\n\t# 정렬\r\n    def heapify(self): # 재정렬\r\n        idx = 0\r\n        while 2*idx + 1 < len(self.queue): # 적어도 왼쪽이랑은 비교할 수 았어야 가치가 있다.\r\n            if 2*idx + 2 < len(self.queue) and (self.queue[idx] < self.queue[2*idx + 2] or self.queue[idx] < self.queue[2*idx + 1]): # 양쪽 비교 가능 & 둘 중 하나가 더 큼\r\n                if self.queue[2*idx + 2] > self.queue[2*idx + 1]:\r\n                    self.queue[idx], self.queue[2*idx + 2] = self.queue[2*idx + 2], self.queue[idx]\r\n                    idx = 2*idx + 2\r\n                else:\r\n                    self.queue[idx], self.queue[2*idx + 1] = self.queue[2*idx + 1], self.queue[idx]\r\n                    idx = 2*idx + 1\r\n            elif self.queue[idx] < self.queue[2*idx + 1]: # 왼쪽 자식만 비교\r\n                self.queue[idx], self.queue[2*idx + 1] = self.queue[2*idx + 1], self.queue[idx]\r\n                idx = 2*idx + 1\r\n            else:\r\n                break\r\n        # 근데 만약 왼쪽부터 바꿔버렸는데, 오른쪽 자식이 더 컸다면?\r\n        if len(self.queue) > 2 and self.queue[0] < self.queue[2]:\r\n            self.heapify()\r\n\r\n\t# 출력\r\n    def show(self):\r\n        print(self.queue)\r\n```\r\n\r\n```python\r\n# 힙푸쉬\r\ndef heap_push(item):\r\n    global heap_count\r\n    heap_count += 1\r\n    heap[heap_count] = item\r\n\r\n    cur = heap_count\r\n    parent = cur // 2\r\n\r\n    #최소힙을 만족하기 위해서 루트이면 멈추게끔, 부모와 자식 비교\r\n    while parent and heap[parent] > heap[cur]:\r\n        heap[parent],heap[cur] = heap[cur],heap[parent]\r\n        cur = parent\r\n        parent = cur // 2\r\n\r\n# 힙팝\r\ndef heap_pop():\r\n    global heap_count\r\n    item = heap[1]\r\n    heap[1] = heap[heap_count]\r\n    heap_count -= 1\r\n\r\n    parent = 1\r\n    child = parent * 2\r\n    if child + 1 <= heap_count:\r\n        if heap[child] > heap[child+1]:\r\n            child = child+1\r\n\r\n    while child <= heap_count and heap[parent]> heap[child]:\r\n        heap[parent],heap[child] = heap[child], heap[parent]\r\n        parent = child\r\n        child = parent * 2\r\n        if child + 1 <= heap_count:\r\n            if heap[child] > heap[child+1]:\r\n                child = child+1\r\n\r\n    return item\r\n```\r\n\r\n\r\n\r\n\r\n\r\n# Searching\r\n\r\n## 선형 탐색\r\n\r\n\r\n\r\n## 이진 탐색 (Binary Search)\r\n\r\n> 정렬된 자료에 사용 가능\r\n\r\nhttps://velog.io/@keum0821/%EC%9D%B4%EC%A7%84-%ED%83%90%EC%83%89-%ED%8A%B8%EB%A6%ACBinary-Search-Tree-%EA%B5%AC%ED%98%84-%EC%82%AD%EC%A0%9C\r\n\r\n- 탐색\r\n\r\n1. 중앙값을 선택\r\n2. 목표값과 비교\r\n3. 목표값과 일치하면 탐색 종료\r\n4. 목표값이 더 작으면 왼쪽 자료에 대해 탐색, 더 크면 오른쪽 자료에 대해 탐색\r\n5. 위의 과정 반복\r\n\r\n- 삼입\r\n\r\n1. 루트 노드부터 아래로 탐색 수행\r\n2. 탐색 실패 위치에 원소 삽입\r\n\r\n- 삭제\r\n  - 자식 노드가 0\r\n    1. 그냥 삭제\r\n  - 자식 노드가 1\r\n    1. 원소 삭제\r\n    2. 자손 노드를 하나씩 위로\r\n  - 자식 노드가 2\r\n    1. 원소 삭제\r\n    2. <u>왼쪽 서브 트리의 가장 오른쪽 자손 노드와 교체</u> or <u>오른쪽 서브 트리의 가장 왼쪽 자손 노드와 교체</u>\r\n\r\n\r\n\r\n\r\n\r\n# Recursion\r\n\r\n함수 내부에서 직간접적으로 자기자신을 호출하는 행위\r\n\r\n- 반복에 비해 코드가 간결, 이해가 쉬움\r\n- 메모리 구조에서 스택을 사용\r\n- 재귀 호출은 메모리, 속도 저하 발생\r\n\r\n## 반복 VS 재귀\r\n\r\n|                | 재귀                      | 반복                |\r\n| -------------- | ------------------------- | ------------------- |\r\n| 종료           | base case(호출 종료) 조건 | 반복문의 종료 조건  |\r\n| 수행 시간      | 느림                      | 빠름                |\r\n| 메모리 공간    | 많이 사용                 | 적게 사용           |\r\n| 소스 코드 길이 | 짧다                      | 길다                |\r\n| 소스 코드 형태 | if-else                   | for, while          |\r\n| 무한 반복시    | 스택 오버플로우           | CPU를 반복해서 점유 |\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n# Graph\r\n\r\n## 그래프 유형\r\n\r\n- 무향 그래프\r\n- 유향 그래프\r\n- 가중치 그래프(weighted gragh)\r\n- 사이클이 없는 방향 그래프(Directed Acyclic Graph)\r\n\r\n\r\n\r\n- 완전 그래프 : 모든 정점이 모든 정점과 이어진 간선을 가진 그래프\r\n\r\n\r\n\r\n- 그래프의 표현\r\n  - 인접 행렬 : V x V의 2차원 배열\r\n    - 장점 : 쉬운 구현, 두 노드의 연결을 확인할 때 O(1) 소요\r\n    - 단점 : 특정 노드에 연결된 노드를 확인하려면 O(V) 소요\r\n  - 인접 리스트 : 각 정점마다 간선 정보를 저장\r\n    - 장점 : 적은 메모리 사용, 간선 파악에 간선 개수만큼만 시간 소요\r\n    - 단점 : 두 노드의 연결을 확인하려면 O(V) 소요\r\n\r\n\r\n\r\n## 그래프 순회\r\n\r\n> 모든 정점을 탐색\r\n\r\n### DFS & BFS\r\n\r\n- DFS : stack, 재귀를 사용\r\n\r\n- BFS : queue를 사용\r\n\r\n\r\n\r\n## 상호배타 집합 자료구조 (Disjoint-sets)\r\n\r\n> 서로소 집합\r\n>\r\n> 중복이 없는 집합들 (교집합이 공집합)\r\n\r\n### 표현 방법\r\n\r\n- 연결 리스트 : representative로 시작, tail로 끝남\r\n- 트리 : representative(루트 노드) 아래의 자식 노드로 구성\r\n\r\n### 연산\r\n\r\n- `Make-Set(x)` - 유일한 멤버 x를 포함하는 새로운 집합 생성\r\n- `Find-Set(x)` - x를 포함하는 집합 탐색, return representative\r\n\r\n- `Union(x, y)` - x와 y를 포함하는 두 집합을 통합 / 집합 y의 대표를 집합 x의 대표로 바꾸는 것\r\n\r\n### Rank / Path compression <= `연산의 효율을 높이는 방법`\r\n\r\n> 트리의 높이가 높아지면 연산 속도가 저하된다. 이렇게 높이가 높아지는 것을 막기 위해 2가지 방법이 있다.\r\n\r\n- 두 집합을 더할 땐 작은 집합을 큰 집합의 높이 위치에 더한다(`rank`)\r\n\r\n  -  리프의 높이를 0이라고 가정하고, 작은 집합의 루트를 큰 집합에서 동일한 높이의 위치에 붙인다\r\n\r\n    ![8장. 상호 배타적 집합의 처리. - ppt download](https://slidesplayer.org/slide/16203848/95/images/17/%2B+%3D+%EB%9E%AD%ED%81%AC%EB%A5%BC+%EC%9D%B4%EC%9A%A9%ED%95%9C+Union%EC%9D%98+%EC%98%88+c+e+c+b+h+d+f+b+h+e+a+a+d+f.jpg)\r\n\r\n  - 만약 두 집합의 높이가 동일하다면, 한 집합의 루트 노드의 높이를 하나 높이고, 다른 집합을 그 루트 아래에 연결\r\n\r\n- <u>find-set 과정</u>에서 만나는 모든 원소를 root에 연결한다(`path compression`)\r\n\r\n\r\n\r\n## 최소 신장 트리 (Minimum Spanning Tree)\r\n\r\n> 탐욕 기법 이용\r\n>\r\n> 최소 비용의 경로를 찾는 문제 (가중치의 합이 최소)\r\n\r\n- 신장 트리\r\n  - `n개의 정점`과 `n-1개의 간선`으로 이루어진 `무향 그래프`\r\n- 최소 신장 트리 (MST)\r\n  - 무향 가중치 그래프에서 신장 트리의 간선들의 **가중치 합이 최소**인 신장 트리\r\n\r\n### KRUSKAL 알고리즘\r\n\r\n- **트리의 모든 간선을 대상으로 최소 비용 간선을 하나씩 선택**\r\n  1. 먼저, 모든 간선을 가중치에 따라 `오름차순 정렬`\r\n  2. `가중치가 낮은 간선부터` 신장 트리 증가 - 해당 간선을 선택했을 때 `사이클`이 만들어지면 `pass`\r\n  3. 2를 반복\r\n\r\n\r\n\r\n#### `이걸 상호 배타 집합을 어떻게 활용하나?`\r\n\r\n각 노드마다 상호 배타 집합 형성\r\n\r\n=> 선택한 간선이 연결하는 두 노드가 같은 대표자를 공유하는지 확인 => **`같은 대표자를 공유하면 사이클`**\r\n\r\n\r\n\r\n#### 구현\r\n\r\n```python\r\ndef make_set(x):\r\n    p[x] = x\r\n\r\n\r\n# 효율이 고려된 퐈인드 셋 ㅋ\r\ndef find_set(x):\r\n    if p[x] != x:\r\n        p[x] = find_set(p[x])\r\n    return p[x]\r\n\r\n\r\n# rank 고려 x\r\ndef union(x, y):\r\n    p[find_set(y)] = find_set(x)\r\n\r\n\r\nfor tc in range(1, int(input()) + 1):\r\n    V, E = map(int, input().split())\r\n\r\n    # 간선 입력\r\n    edges = [list(map(int, input().split())) for _ in range(E)]\r\n\r\n    # 크루스칼을 하기 위해서 간선을 가중치 순으로 오름차순 정렬\r\n    edges = sorted(edges, key=lambda x: x[2])\r\n\r\n    p = [0] * (V + 1)\r\n    # p = list(range(V+1))\r\n\r\n    for i in range(V + 1):\r\n        make_set(i)\r\n\r\n    ans = 0\r\n    cnt = 0  # 간선선택회수\r\n    idx = 0  # 간선의 인덱스\r\n\r\n    while cnt < V:\r\n        x = edges[idx][0]\r\n        y = edges[idx][1]\r\n\r\n        if find_set(x) != find_set(y):\r\n            union(x, y)\r\n            cnt += 1\r\n            ans += edges[idx][2]\r\n        idx += 1\r\n    print(\"#{} {}\".format(tc, ans))\r\n```\r\n\r\n\r\n\r\n### PRIM 알고리즘\r\n\r\n- **하나의 정점에서 연결된 간선 중 최소 비용 간선 선택**\r\n  1. 임의의 정점 선택\r\n  2. `인접 정점` 중 `최소 비용`의 간선을 가진 정점 선택 (이 때 대상은 선택한 트리와 인접한 간선 전체가 대상)\r\n  3. 2를 반복\r\n\r\n- **서로소**인 2개의 집합 정보 유지\r\n  - 트리 정점 - MST를 만들기 위해 **선택된 정점들**\r\n  - 비트리 정점 - **선택되지 않은 정점들**\r\n  \r\n  \r\n#### `이걸 상호 배타 집합을 어떻게 활용하나?`\r\n\r\n  `선택 한 노드 집합` VS `선택 안 한 노드 집합`\r\n\r\n  항상 선택 안 한 노드 집합과 연결된 간선을 선택하기 때문에, 사이클 X\r\n\r\n\r\n\r\n#### 구현\r\n\r\n```python\r\ndef Prim():\r\n    dist = [987654321] * (V+1)\r\n    visited = [False]* (V+1)\r\n\r\n    dist[V] = 0\r\n    for _ in range(V):\r\n        min_idx = -1\r\n        min_value = 987654321\r\n\r\n        # 최소 거리인 노드 선택\r\n        for i in range(V+1):\r\n            if not visited[i] and dist[i] < min_value:\r\n                min_idx = i\r\n                min_value = dist[i]\r\n        visited[min_idx] = True\r\n        # 새로 추가된 노드에 대해 거리 갱신\r\n        for i in range(V+1):\r\n            if not visited[i] and adj[min_idx][i] < dist[i]:\r\n                dist[i] = adj[min_idx][i]\r\n\r\n    return sum(dist)\r\n\r\n\r\nfor tc in range(1, int(input())+1):\r\n    V, E = map(int,input().split())\r\n\r\n    adj = [[987654321] * (V+1) for _ in range(V+1)]\r\n\r\n    for i in range(E):\r\n        st, ed, w = map(int, input().split())\r\n        adj[st][ed] = adj[ed][st] = w\r\n\r\n    print(\"#{} {}\".format(tc, Prim()))\r\n```\r\n\r\n\r\n\r\n### ! 근데 MST에서 꼭 서로소 집합(상호 배타 집합)을 써야하는 건 아님 - 상황에 따라\r\n\r\n\r\n\r\n\r\n\r\n## 두 정점 사이의 최단 경로\r\n\r\n### 다익스트라 알고리즘 (Dijkstra)\r\n\r\n- 중점-다른 모든 점까지의 최단 경로\r\n\r\n- 음의 가중치 허용 X\r\n\r\n\r\n\r\n- **시작 정점부터 거리가 최소인 정점을 선택** / 프림 알고리즘과 유사\r\n\r\n```python\r\ndef dijstra():\r\n    dist = [987654321]*(V+1)\r\n    visited = [False] * (V+1)\r\n\r\n    dist[0] = 0\r\n\r\n    for _ in range(V):\r\n        min_idx = -1\r\n        min_value = 987654321\r\n        for i in  range(V+1):\r\n            if not visited[i] and min_value > dist[i]:\r\n                min_value = dist[i]\r\n                min_idx = i\r\n        visited[min_idx] = True\r\n        #갱신할거 개신\r\n        for i in range(V+1):\r\n            if not visited[i] and dist[i] > adj[min_idx][i] + dist[min_idx]:\r\n                dist[i] = adj[min_idx][i] + dist[min_idx]\r\n        print(dist)\r\n    return dist[V]\r\n\r\n\r\nfor tc in range(1, int(input())+1):\r\n    V, E = map(int , input().split())\r\n\r\n    adj = [[987654321]*(V+1) for _ in range(V+1)]\r\n\r\n    for i in range(E):\r\n        st, ed , w = map(int , input().split())\r\n        adj[st][ed] = w\r\n\r\n    print(\"#{} {}\".format(tc, dijstra()))\r\n```\r\n\r\n\r\n\r\n\r\n\r\n### 벨만-포드 알고리즘 (Bellman-Ford)\r\n\r\n- 중점-다른 모든 점까지의 최단 경로\r\n- 음의 가중치 허용\r\n\r\n\r\n\r\n\r\n\r\n### 플로이드-워샬 알고리즘 (Floyd-Warshall)\r\n\r\n- 모든 정점에 대한 최단 경로\r\n- 동적 계획 알고리즘 (DP)\r\n- 모든 부분에 대하여 [`직선거리 vs 경유거리`] 중 짧은 경로 선택을 반복\r\n- 이를 N*N 배열에서 계속 값을 갱신하면서 `O(N^3)` 시간만에 해답 도출\r\n  - 경유, 시작, 끝, 이렇게 3개에 대해서 반복문 3번 돌림\r\n  - 직선이 최단이면 직선 선택, ***경유가 최단이면 경유에 대해서 다시 재귀 호출????***\r\n  - DP적으로 풀면 재귀가 필요 없음\r\n\r\n\r\n\r\n```python\r\nimport sys\r\ninput = sys.stdin.readline\r\n\r\nN, M = map(int, input().split())\r\n\r\nfloyd_warshall = [[100]*N for _ in range(N)] # 최대 99\r\n\r\nfor i in range(N):\r\n    floyd_warshall[i][i] = 0\r\n\r\nfor _ in range(M):\r\n    a,b = map(int, input().split())\r\n    floyd_warshall[a-1][b-1] = 1\r\n    floyd_warshall[b-1][a-1] = 1\r\n\r\nlocal_mins = 100\r\nlocal_min_idx = -1\r\n\r\nfor m in range(N):\r\n    for i in range(N):\r\n        for j in range(N):\r\n            floyd_warshall[i][j] = min(floyd_warshall[i][j], floyd_warshall[i][m]+floyd_warshall[m][j])\r\n    \r\nfor i in range(N):\r\n    kevin_bacon = sum(floyd_warshall[i])\r\n    if local_mins > kevin_bacon:\r\n        local_mins = kevin_bacon\r\n        local_min_idx = i\r\n\r\nprint(local_min_idx+1)\r\n```\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n# Exhaustive Search\r\n\r\n가능한 모든 경우의 수를 나열 -> 확인하는 기법\r\n\r\n- 완전 탐색, Brute-force라고 불리기도 한다\r\n\r\n\r\n\r\n# Greedy\r\n\r\n최적의 해를 구하는 근시안적인 방법\r\n\r\n그 순간의 최적을 선택하는 방식\r\n\r\n- <u>해당 탐욕 기법이 최적해로 가는 경로인지 증명이 필요</u>\r\n\r\n\r\n\r\n## 탐욕 기법 vs 동적 계획법\r\n\r\n| 탐욕 기법   | 동적 계획법 |\r\n| ----------- | ----------- |\r\n| Top-down    | Bottom-up   |\r\n| 빠르고 간결 | 느리고 복잡 |\r\n\r\n\r\n\r\n## 활동 선택 문제 (Activity-Selection problem)\r\n\r\n시작시간과 종료시간이 있는 n개의 활동들의 집합에서, 겹치지 않는 최대 갯수를 구하는 문제\r\n\r\n```\r\n1. 종료 시간 순으로 정렬\r\n\r\n2. 종료 시간이 가장 빠른 활동을 선택\r\n\r\n3. 이후 선택한 활동 이후에 종료 시간이 가장 빠른 활동을 선택을 반복\r\n```\r\n\r\n\r\n\r\n## 탐욕 기법의 알고리즘\r\n\r\n- `Prim` : **최소 신장 트리 탐색** - 서브 트리를 확장하면서 탐색\r\n- `Kruskal` : **최소 신장 트리 탐색** - Cycle이 없는 서브 그래프를 확장하면서 탐색\r\n- `Dijkstra` : **최단 경로 탐색** - 가장 가까운 인접 정점을 찾는 방식\r\n- `Huffman tree & code` : **압축** - 빈도가 낮은 문자부터 이진 트리를 만들어 코드값 부여\r\n\r\n\r\n\r\n\r\n\r\n# Divide and Conquer\r\n\r\n`Divide - Conquer - Combine`\r\n\r\nDivide : 문제를 여러 개의 부분으로 나눔\r\n\r\nConquer : 작은 부분 문제를 해결\r\n\r\nCombine : 해결된 해답을 모은다 `(선택)`\r\n\r\n\r\n\r\n\r\n\r\n# Backtacking\r\n\r\n**유망성 검사를 통해 <u>유망성</u>이 없는 경로를 제외하는 기법**\r\n\r\n- 보통 `재귀함수-DFS`로 구현\r\n- 해를 얻을 때 까지 시도\r\n- 기본적으로 `완전탐색 + DFS + 유망성 탐색` 구조\r\n\r\n```\r\n[과정]\r\n1. 유망성 검사 => False 면 return\r\n2. 해답 검사 => True면 해 return\r\n3. 자식 노드로 이동\r\n```\r\n\r\n\r\n\r\n## 완전탐색 DFS와의 차이점\r\n\r\n백트래킹은 유망성 검사를 통해 **가지치기(Pruning)**을 한다는 특징이 있다.\r\n\r\n* 하지만 <u>최악의 경우에는 완전탐색과 같은 시간이 걸릴 수도 있음</u>\r\n\r\n\r\n\r\n\r\n\r\n# Dynamic Programming\r\n\r\n- 메모이제이션 활용\r\n- 2가지 요건이 필수적\r\n  - 중복 부분 문제 : 반복 계산\r\n  - 최적 부분 문제 : 어떤 문제의 최적해가 그 문제를 구성하는 작은 문제들의 최적해로 구성되는 것\r\n\r\n\r\n\r\n## 분할 정복 VS DP\r\n\r\n- 분할 정복\r\n  - 연관 없는 부분 문제로 분할\r\n  - 재귀적인 문제 해결\r\n  - 하향식 접근\r\n- DP\r\n  - 연관된 부분 문제\r\n  - 부분 문제를 한 번만 계산, 저장\r\n  - 부분 문제들 사이에 의존적 관계가 존재\r\n  - 상향식 접근\r\n\r\n\r\n\r\n\r\n\r\n# Math\r\n\r\n> 어떤 문제는 최적해를 구할 수 없음 => 근사 알고르짐과 확률적 접근이 필요\r\n\r\n- NP 완전 문제들은 다항식 시간 안에 해결 불가\r\n  - 해결을 위해서는 3가지 중 1가지를 포기해야 함\r\n    - 다항식 시간에 해를 찾는 것\r\n    - 모든 입력에 대한 해를 찾는 것\r\n    - 최적해를 찾는 것\r\n  - 여기서 3번을 포기한 것이 `근사 알고리즘`\r\n\r\n## 문제\r\n\r\n- `여행자 문제` : **크루스칼 / 프림 알고리즘**으로 MST => 근사해\r\n- `작업 스케줄링` 문제 : **그리디** => 근사해\r\n\r\n\r\n\r\n## 정수론\r\n\r\n### 최대공약수\r\n\r\n- 유클리드 알고리즘\r\n\r\n```python\r\ndef gcd(a, b):\r\n    if a < b:\r\n    \ta, b = b, a\r\n    while b != 0:\r\n        a, b = b, a % b\r\n    return a\r\n```\r\n\r\n### 최대공배수\r\n\r\n- 유클리드 호제법\r\n\r\n```python\r\ndef lcm(a, b):\r\n    return a*b//gcd(a,b)\r\n```\r\n\r\n### 소수\r\n\r\n- 소수로만 시도\r\n\r\n- N^0.5까지만 시도\r\n- 2 이후로는 홀수만 시도\r\n\r\n- 에라토스테네스의 체\r\n\r\n\r\n\r\n\r\n\r\n#  Probablity\r\n\r\n## 모의 담금질\r\n\r\n> 해를 찾기 위한 확률적인 접근\r\n\r\n높은 T에서는 원자들이 자유로움 => 낮은 T로 가면 원자들이 규칙성을 띔\r\n\r\n\r\n\r\n\r\n\r\n# Combination & Permutation\r\n\r\n## 순열 (Permutation)\r\n\r\n### 생성 방법\r\n\r\n1. 반복문\r\n2. 재귀 호출\r\n3. 비트마스킹 (비트연산자 사용) - 재귀\r\n\r\n4. **NextPermutation** / <u>사전 순(오름차순)으로 다음 번 순열을 찾는 방법</u>\r\n   1. 뒤쪽부터 탐색하면 `교환위치(i-1)` 찾기\r\n   2. `교환 위치(i-1)`와 교환할 `큰 값 위치(j)` 찾기\r\n   3. `i-1`, `j` 교환\r\n   4. `꼭대기(i)`부터 맨 뒤까지 오름차순 정렬\r\n   5. 반복\r\n\r\n- 예시\r\n  - 1234\r\n  - 12**43**\r\n  - 1**32**4\r\n  - ...\r\n  - 4321\r\n    - 1324\r\n    - 13**42**\r\n    - ...\r\n      - 1342\r\n      - ...\r\n        - ...\r\n\r\n\r\n\r\n## 조합 (Combination)\r\n\r\n### 생성방법\r\n\r\n1. 반복문\r\n\r\n2. 재귀 호출\r\n\r\n3. NextPermutation\r\n\r\n   `1 2 3 4`\r\n\r\n    0  0  1  1\r\n\r\n    0  1  0  1\r\n\r\n    0  1  1  0\r\n\r\n    1  0  0  1\r\n\r\n    1  0  1  0\r\n\r\n    1  1  0  0\r\n\r\n\r\n\r\n## 부분집합\r\n\r\n### 생성방법\r\n\r\n1. 반복문\r\n2. 재귀 호출\r\n3. **바이너리 카운팅 (가장 좋은 방법)**\r\n\r\n   n개의 원소를 갖고 있는 집합의 부분집합 개수는 2^n개\r\n\r\n   (있다or없다, 있다or없다, ...)\r\n\r\n   `i & (1<<j)` 를 이용해 i의 j번째 원소가 1인지 판별 가능\r\n\r\n   이를 이용해서\r\n\r\n   ```python\r\n   lst = ['a','b','c','d']\r\n   N = 4\r\n   for i in range(1<<N): # 1<<N은 2의 N제곱\r\n       ans = ''\r\n       for j in range(N):\r\n           if i & (1<<j):\r\n               ans += lst[j] + \" \"\r\n       print(ans)\r\n   ```\r\n\r\n   이렇게 부분 집합 구현 가능\r\n\r\n\r\n\r\n# KMP 알고리즘\r\n\r\n> 꼭 알아야 하는 문자열 알고리즘\r\n>\r\n> Knuth-Morris-Pratt Algorithm\r\n\r\nhttps://bowbowbow.tistory.com/6\r\n\r\nhttps://snupi.tistory.com/88\r\n\r\n- 불일치가 발생하면 앞부분을 비교하지 않고 매칭 수행\r\n- 패턴을 전처리 해서 `fail[k]`를 구함\r\n  - 패턴 내에서 반복되는 값을 파악해서 매칭 실패시 돌아갈 위치를 지정\r\n- 시간복잡도 `O(M+N)`\r\n\r\n\r\n\r\n## 전처리 과정\r\n\r\n패턴의 **맨 앞부분**과, **맨 뒷부분**에서 <u>동일한 모양</u> 중 <u>가장 긴 길이</u>만큼 숫자 배정\r\n\r\n`AABAABAC`\r\n\r\n`01012340`\r\n\r\nA와 A -> 1\r\n\r\nA와 B -> 0\r\n\r\nA와 A -> 1\r\n\r\nAA와 AA -> 2\r\n\r\nAAB와 AAB -> 3\r\n\r\nAABA와 AABA -> 4\r\n\r\nA와 C -> 0\r\n\r\n## 동작과정\r\n\r\n전처리 후 얻어지는 숫자들은 매칭에서 틀렸을 때, 다음번 비교에서 비교할 패턴의 문자를 가리킴\r\n\r\n\r\n\r\n## 코드\r\n\r\n```python\r\ndef preprocessing(data):\r\n    preprocessed = [0]*len(data)\r\n    offset = 1 # 보정 값\r\n    matched = 0 # matched된 길이\r\n    while offset+matched < len(data):\r\n        if data[offset+matched] == data[matched]:\r\n            preprocessed[offset+matched] = matched+1\r\n            matched += 1\r\n        elif matched: # offset+matched는 그대로(같은 걸 조사) => \r\n            offset += matched - preprocessed[matched-1] # 다음 조사 대상을 유지하기 위해 offset 보정\r\n            matched = preprocessed[matched-1] # 이전 걸로 돌아가기\r\n        else: # 일단 다음 걸 조사해야 하기 때문에 전진\r\n            offset += 1\r\n    return preprocessed\r\n\r\n\r\ndef KMP(input_data):\r\n    idx = 0\r\n    idx_t = 0\r\n    left = len(input_data)\r\n    t_length = len(target_data)\r\n\r\n    res = []\r\n    while idx <= left-t_length:\r\n        adder = 0\r\n        while idx_t < t_length and idx+adder < left:\r\n            if input_data[idx+adder] == target_data[idx_t]:\r\n                idx_t += 1\r\n                adder += 1\r\n            else:\r\n                if idx_t:\r\n                    idx_t = preprocessed[idx_t-1]\r\n                    idx += adder\r\n                    adder = 0\r\n                    continue\r\n                break\r\n        if idx_t == t_length:\r\n            res.append(idx)\r\n            idx += t_length-1\r\n            idx_t = 0\r\n        idx += 1\r\n    \r\n    return res\r\n\r\ninput_data = input()\r\ntarget_data = input()\r\npreprocessed = preprocessing(target_data)\r\nprint(preprocessed)\r\nprint(KMP(input_data))\r\n\r\n\r\n# AABAAABAABBBBABBABBABAABAAABAABBAABAB\r\n# AABAAABAABB\r\n\r\n# [0, 1, 0, 1, 2, 2, 3, 4, 5, 3, 0]\r\n# [0, 21]\r\n\r\n### for로 구현\r\ndef preprocessing(data):\r\n    preprocessed = [0]*len(data)\r\n\r\n    for i in range(1,len(data)):\r\n        preprocessed[i] = preprocessed[i-1]\r\n        while preprocessed[i]>=0:\r\n            if data[i] == data[preprocessed[i]]:\r\n                preprocessed[i] += 1\r\n                break\r\n            preprocessed[i] = preprocessed[preprocessed[i]-1]\r\n            if not preprocessed[i]:\r\n                break\r\n\r\n    return preprocessed\r\n```\r\n\r\n\r\n\r\n\r\n\r\n# 데이터 압축\r\n\r\n- Run-Length Encoding : 동일한 값이 얼마나 반복되는지 확인\r\n- `Huffman Coding` : 기호의 **빈도**, **허프만 트리**\r\n- Lampel-Ziv-Welch Encoding\r\n- Arithmetic Coding\r\n\r\n\r\n\r\n\r\n\r\n# 최적화\r\n\r\n1. *unsigned > signed*\r\n2. int > float\r\n3. 곱셈 > 나눗셈\r\n4. 수학 공식 > 단순 연산\r\n5. 비트 연산 짝수 홀수 확인 > 모듈러 연산\r\n6. 반복문 > 모듈러 연산\r\n7. 함수 호출 최소화\r\n8. 비트연산 활용\r\n9. 풀어쓰기 > 반복문\r\n10. <u>최적화는 마지막</u> / 최선은 **좋은 알고리즘 선택**","documentTitle":"알고리즘 & 자료구조 정리"},"__N_SSG":true}